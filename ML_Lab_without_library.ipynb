{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Lab without library.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.\tWrite python programs to predict diabetes using logistic regression. Implement the algorithm using library and without using library. Implement batch gradient descent. Find accuracy, precision, recall, F1-score, and specificity and compare both strategies (Use diabetes.csv). Assume train/test split is 70:30."
      ],
      "metadata": {
        "id": "_0ord0FM098b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A6Bh0T40zGI"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data handeling\n",
        "from sklearn.model_selection import train_test_split # splitting data in train/test set\n",
        "from scipy.special import expit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0 / (1 + np.exp(-z))\n",
        "\n",
        "def predict(features, weights):\n",
        "  '''\n",
        "  Returns 1D array of probabilities\n",
        "  that the class label == 1\n",
        "  '''\n",
        "  z = np.dot(features, weights)\n",
        "  return sigmoid(z)"
      ],
      "metadata": {
        "id": "LZ4I7Tui3B0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(features, labels, weights, lr):\n",
        "    '''\n",
        "    Vectorized Gradient Descent\n",
        "\n",
        "    Features:(200, 3)\n",
        "    Labels: (200, 1)\n",
        "    Weights:(3, 1)\n",
        "    '''\n",
        "    N = len(features)\n",
        "\n",
        "    #1 - Get Predictions\n",
        "    predictions = predict(features, weights)\n",
        "\n",
        "\n",
        "    #2 Transpose features from (200, 3) to (3, 200)\n",
        "    # So we can multiply w the (200,1)  cost matrix.\n",
        "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
        "    # one for each feature -- representing the aggregate\n",
        "    # slope of the cost function across all observations\n",
        "    gradient = np.dot(features.T,  predictions - labels)\n",
        "\n",
        "    #3 Take the average cost derivative for each feature\n",
        "    gradient /= N\n",
        "\n",
        "    #4 - Multiply the gradient by our learning rate\n",
        "    gradient *= lr\n",
        "\n",
        "    #5 - Subtract from our weights to minimize cost\n",
        "    weights -= gradient\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "U4SiaNtxxSzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_boundary(prob):\n",
        "  return 1 if prob >= .5 else 0"
      ],
      "metadata": {
        "id": "yRwwKw0sxZTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(predictions):\n",
        "  '''\n",
        "  input  - N element array of predictions between 0 and 1\n",
        "  output - N element array of 0s (False) and 1s (True)\n",
        "  '''\n",
        "  decision_boundarys = np.vectorize(decision_boundary)\n",
        "  return decision_boundarys(predictions)"
      ],
      "metadata": {
        "id": "iAycBTTDxaCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(features, labels, weights, lr, iters):\n",
        "    for i in range(iters):\n",
        "        weights = update_weights(features, labels, weights, lr)\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "uknRXXiUxcqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predicted_labels, actual_labels):\n",
        "    diff = predicted_labels - actual_labels\n",
        "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))\n",
        "\n",
        "def precision(predicted_labels, actual_labels):\n",
        "    connected_result = zip(predicted_labels, actual_labels.values)\n",
        "    both_ones = 0\n",
        "    first_one = 0\n",
        "    for prediction, actual in connected_result:\n",
        "        if (prediction[0] == 1) & (actual[0] == 1):\n",
        "            both_ones += 1\n",
        "        if (prediction[0] == 1) & (actual[0] != 1):\n",
        "            first_one += 1\n",
        "\n",
        "    TP = both_ones\n",
        "    FP = first_one\n",
        "\n",
        "    return (TP)/ (TP+FP)\n",
        "\n",
        "def recall(predicted_labels, actual_labels):\n",
        "    connected_result = zip(predicted_labels, actual_labels.values)\n",
        "    both_ones = 0\n",
        "    total_ones = 0\n",
        "    for prediction, actual in connected_result:\n",
        "        if (prediction[0] == 1) & (actual[0] == 1):\n",
        "            both_ones += 1\n",
        "        if (actual[0] == 1):\n",
        "            total_ones += 1\n",
        "\n",
        "    return both_ones / total_ones\n",
        "\n",
        "def f1_score(predicted_labels, actual_labels):\n",
        "    precision_score = precision(predicted_labels, actual_labels)\n",
        "    recall_score = recall(predicted_labels, actual_labels)\n",
        "\n",
        "    return (2 * precision_score * recall_score) / (precision_score + recall_score)\n",
        "\n",
        "def specificity(predicted_labels, actual_labels):\n",
        "    connected_result = zip(predicted_labels, actual_labels.values)\n",
        "    both_zeroes = 0\n",
        "    ones_zeroes = 0\n",
        "    for prediction, actual in connected_result:\n",
        "        if (prediction[0] == 0) & (actual[0] == 0):\n",
        "            both_zeroes += 1\n",
        "        if (prediction[0] == 1 & actual[0] == 0):\n",
        "            ones_zeroes += 1\n",
        "\n",
        "    return both_zeroes / (both_zeroes + ones_zeroes)\n"
      ],
      "metadata": {
        "id": "ytsHpAz1xwm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"Diabetes.csv\")\n",
        "\n",
        "features = ['Pragnency', 'Glucose', 'Blod Pressure', 'Skin Thikness', 'Insulin', 'BMI', 'DFP', 'Age']\n",
        "x = df.loc[:, features]\n",
        "y = df.loc[:, ['Diabetes']]\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
      ],
      "metadata": {
        "id": "A01kU2nSy0BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.zeros([8, 1])\n",
        "weights = train(X_train, Y_train, weights, 0.1, 1000) #train(features, labels, weights, lr, iters)\n",
        "predictions = predict(X_test, weights)\n",
        "classifications = classify(predictions)\n",
        "\n",
        "accuracy_result = accuracy(classifications, Y_test)\n",
        "precision_result = precision(classifications, Y_test)\n",
        "recall_result = recall(classifications, Y_test)\n",
        "f1_result = f1_score(classifications, Y_test)\n",
        "specificity_result = specificity(classifications, Y_test)\n",
        "\n",
        "print(\"Accuracy = {0}\".format(str(accuracy_result)))\n",
        "print(\"Precision = {0}\".format(str(precision_result)))\n",
        "print(\"Recall = {0}\".format(str(recall_result)))\n",
        "print(\"F1 Score = {0}\".format(str(f1_result)))\n",
        "print(\"Specificity Score = {0}\".format(str(specificity_result)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KceaR3izPQ5",
        "outputId": "85858136-03a7-47bc-ee92-60b8e7facec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.4025974025974026\n",
            "Precision = 0.3382352941176471\n",
            "Recall = 0.9583333333333334\n",
            "F1 Score = 0.5\n",
            "Specificity Score = 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "58nM7vmyzAij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}