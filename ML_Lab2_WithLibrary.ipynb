{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Lab2 WithLibrary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.\tWrite python programs to predict diabetes using logistic regression. Implement the algorithm using library and without using library. Implement batch gradient descent. Find accuracy, precision, recall, F1-score, and specificity and compare both strategies (Use diabetes.csv). Assume train/test split is 70:30."
      ],
      "metadata": {
        "id": "MaGdIZl9BbsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tWUTU2IrKD_"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "FUelZqzdtkM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Diabetes.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeEJC-dFrPQt",
        "outputId": "133db141-429d-46f4-cb75-709ad535e4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 767 entries, 0 to 766\n",
            "Data columns (total 9 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Pragnency      767 non-null    int64  \n",
            " 1   Glucose        767 non-null    int64  \n",
            " 2   Blod Pressure  767 non-null    int64  \n",
            " 3   Skin Thikness  767 non-null    int64  \n",
            " 4   Insulin        767 non-null    int64  \n",
            " 5   BMI            767 non-null    float64\n",
            " 6   DFP            767 non-null    float64\n",
            " 7   Age            767 non-null    int64  \n",
            " 8   Diabetes       767 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = df.drop('Diabetes',axis=1) #columns\n",
        "y = df['Diabetes']\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "37UC31CIvlPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logmodel = LogisticRegression(solver= 'lbfgs' , max_iter=1000 )  #L-BFGS Scorer\n",
        "logmodel.fit(x_train,y_train)\n",
        "\n",
        "#sklearn.metrics. accuracy_score(y_test,y_pred)\n",
        "\n",
        "predictions = logmodel.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,predictions))\n",
        "#print(accuracy_score(y_test, predictions))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYMuxyBQvnwy",
        "outputId": "ac0eb470-1aa3-40e8-da6f-f9c176b15267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       159\n",
            "           1       0.65      0.57      0.61        72\n",
            "\n",
            "    accuracy                           0.77       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.76      0.77      0.77       231\n",
            "\n"
          ]
        }
      ]
    }
  ]
}